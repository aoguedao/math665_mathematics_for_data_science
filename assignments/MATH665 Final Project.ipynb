{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# MATH665\n",
    "\n",
    "_Shraddha Rajpal and Alonso Ogueda_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "CvYHSX8XfUke"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "rng = np.random.default_rng(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "rVOrk6RHglC6"
   },
   "outputs": [],
   "source": [
    "# Data\n",
    "x1 = np.array([0.1, 0.3, 0.1, 0.6, 0.4, 0.6, 0.5, 0.9, 0.4, 0.7])\n",
    "x2 = np.array([0.1, 0.4, 0.5, 0.9, 0.2, 0.3, 0.6, 0.2, 0.4, 0.6])\n",
    "y = np.stack(\n",
    "    [\n",
    "      np.concatenate([np.ones(5), np.zeros(5)]),\n",
    "      np.concatenate([np.zeros(5), np.ones(5)])\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_SmRwsxzutOF",
    "outputId": "f0030397-ae5f-4383-e80a-98fe5de7f2a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(PCG64)\n"
     ]
    }
   ],
   "source": [
    "print(rng)\n",
    "# Initialize weights and biases\n",
    "W2 = 0.5 * rng.normal(size=(2, 2))\n",
    "W3 = 0.5 * rng.normal(size=(3, 2))\n",
    "W4 = 0.5 * rng.normal(size=(2, 3))\n",
    "b2 = 0.5 * rng.normal(size=(2, 1))\n",
    "b3 = 0.5 * rng.normal(size=(3, 1))\n",
    "b4 = 0.5 * rng.normal(size=(2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "JslQ8vT1utzf"
   },
   "outputs": [],
   "source": [
    "# Forward and Back propagate\n",
    "eta = 0.05  # learning rate\n",
    "Niter = int(1e2)  # number of SG iterations\n",
    "savecost = np.zeros(Niter)  # value of cost function at each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "IvjuGQG36-6T"
   },
   "outputs": [],
   "source": [
    "def activate(x, W, b):\n",
    "    \"\"\"\n",
    "    Evaluates sigmoid function.\n",
    "    \n",
    "    x is the input vector, y is the output vector\n",
    "    W contains the weights, b contains the shifts\n",
    "\n",
    "    The ith component of y is activate((Wx+b)_i) where activate(z) = 1/(1+exp(-z))\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-(W @ x + b)))\n",
    "\n",
    "def cost(x1, x2, y, W2, W3, W4, b2, b3, b4):\n",
    "    n = len(x1)\n",
    "    costvec = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        x = np.array([[x1[i]], [x2[i]]])\n",
    "        a2 = activate(x, W2, b2)\n",
    "        a3 = activate(a2, W3, b3)\n",
    "        a4 = activate(a3, W4, b4)\n",
    "        costvec[i] = np.linalg.norm(y[:, [i]] - a4, 2)\n",
    "    costval = np.linalg.norm(costvec, 2) ** 2\n",
    "    return costval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ji2WLCL2vGgz",
    "outputId": "d9e9a6eb-a239-4af9-f8e7-45fde7429202",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-th iteration costs: 5.329313666793336\n",
      "2-th iteration costs: 5.333078196439873\n",
      "3-th iteration costs: 5.336958565116635\n",
      "4-th iteration costs: 5.340988736537699\n",
      "5-th iteration costs: 5.345139673910409\n",
      "6-th iteration costs: 5.3357852191229185\n",
      "7-th iteration costs: 5.326669165670839\n",
      "8-th iteration costs: 5.317723540114195\n",
      "9-th iteration costs: 5.308982901730435\n",
      "10-th iteration costs: 5.300422792121799\n",
      "11-th iteration costs: 5.304123205512615\n",
      "12-th iteration costs: 5.2956286369945476\n",
      "13-th iteration costs: 5.299348667764909\n",
      "14-th iteration costs: 5.303172888773429\n",
      "15-th iteration costs: 5.3071262091165226\n",
      "16-th iteration costs: 5.311228644096856\n",
      "17-th iteration costs: 5.302322106709218\n",
      "18-th iteration costs: 5.306409166147501\n",
      "19-th iteration costs: 5.29751809032402\n",
      "20-th iteration costs: 5.288870436801431\n",
      "21-th iteration costs: 5.292847603895492\n",
      "22-th iteration costs: 5.284246622489338\n",
      "23-th iteration costs: 5.2758065058139945\n",
      "24-th iteration costs: 5.2676101461300995\n",
      "25-th iteration costs: 5.271372946599233\n",
      "26-th iteration costs: 5.263219402816917\n",
      "27-th iteration costs: 5.255291286627442\n",
      "28-th iteration costs: 5.247579182065973\n",
      "29-th iteration costs: 5.251066635378056\n",
      "30-th iteration costs: 5.243407230779594\n",
      "31-th iteration costs: 5.235995415089072\n",
      "32-th iteration costs: 5.228763663483756\n",
      "33-th iteration costs: 5.232006087096113\n",
      "34-th iteration costs: 5.235376235458254\n",
      "35-th iteration costs: 5.238889841027668\n",
      "36-th iteration costs: 5.231368756111608\n",
      "37-th iteration costs: 5.224070009201111\n",
      "38-th iteration costs: 5.227461777333129\n",
      "39-th iteration costs: 5.230986753949146\n",
      "40-th iteration costs: 5.234675553485834\n",
      "41-th iteration costs: 5.227045584422535\n",
      "42-th iteration costs: 5.2196945876132075\n",
      "43-th iteration costs: 5.223248827322573\n",
      "44-th iteration costs: 5.226932646563029\n",
      "45-th iteration costs: 5.21942502341887\n",
      "46-th iteration costs: 5.223111554285876\n",
      "47-th iteration costs: 5.226938434342415\n",
      "48-th iteration costs: 5.219321105445426\n",
      "49-th iteration costs: 5.223149643362624\n",
      "50-th iteration costs: 5.215538839797423\n",
      "51-th iteration costs: 5.208165242983596\n",
      "52-th iteration costs: 5.2118429666970005\n",
      "53-th iteration costs: 5.21566210072915\n",
      "54-th iteration costs: 5.208168150153404\n",
      "55-th iteration costs: 5.211997930638306\n",
      "56-th iteration costs: 5.204555744585227\n",
      "57-th iteration costs: 5.20838459784421\n",
      "58-th iteration costs: 5.200976619678041\n",
      "59-th iteration costs: 5.204812572657137\n",
      "60-th iteration costs: 5.208787670984713\n",
      "61-th iteration costs: 5.212899192195087\n",
      "62-th iteration costs: 5.217125715784913\n",
      "63-th iteration costs: 5.209230861436039\n",
      "64-th iteration costs: 5.2134712815213256\n",
      "65-th iteration costs: 5.20561216327141\n",
      "66-th iteration costs: 5.20984649346375\n",
      "67-th iteration costs: 5.214210706745312\n",
      "68-th iteration costs: 5.206239197621573\n",
      "69-th iteration costs: 5.210596902997844\n",
      "70-th iteration costs: 5.215085564999218\n",
      "71-th iteration costs: 5.206956816117599\n",
      "72-th iteration costs: 5.1990956834536215\n",
      "73-th iteration costs: 5.191468853518456\n",
      "74-th iteration costs: 5.184106239104109\n",
      "75-th iteration costs: 5.1769996890281105\n",
      "76-th iteration costs: 5.180890273266688\n",
      "77-th iteration costs: 5.184923589120161\n",
      "78-th iteration costs: 5.177674827841875\n",
      "79-th iteration costs: 5.181712172910201\n",
      "80-th iteration costs: 5.1858935555891925\n",
      "81-th iteration costs: 5.178479805263545\n",
      "82-th iteration costs: 5.182653723093584\n",
      "83-th iteration costs: 5.186963385760049\n",
      "84-th iteration costs: 5.191393480386231\n",
      "85-th iteration costs: 5.195970652256533\n",
      "86-th iteration costs: 5.200677162259823\n",
      "87-th iteration costs: 5.192537846192128\n",
      "88-th iteration costs: 5.197232031668758\n",
      "89-th iteration costs: 5.202053041017009\n",
      "90-th iteration costs: 5.193830851443266\n",
      "91-th iteration costs: 5.198624623557493\n",
      "92-th iteration costs: 5.19041403367823\n",
      "93-th iteration costs: 5.1825097861023774\n",
      "94-th iteration costs: 5.174839837621698\n",
      "95-th iteration costs: 5.1793302147861695\n",
      "96-th iteration costs: 5.171699975546471\n",
      "97-th iteration costs: 5.164330135471447\n",
      "98-th iteration costs: 5.157241193396983\n",
      "99-th iteration costs: 5.161415624494399\n",
      "100-th iteration costs: 5.165745808992688\n"
     ]
    }
   ],
   "source": [
    "n = len(x1)\n",
    "for counter in range(Niter):\n",
    "    k = rng.integers(n)  # choose a training point at random\n",
    "    x = np.array([[x1[k]], [x2[k]]])\n",
    "    # Forward pass\n",
    "    a2 = activate(x, W2, b2)\n",
    "    a3 = activate(a2, W3, b3)\n",
    "    a4 = activate(a3, W4, b4)\n",
    "\n",
    "    # Backward pass\n",
    "    delta4 = a4 * (1 - a4) * (a4 - y[:, [k]])\n",
    "    delta3 = a3 * (1 - a3) * (W4.T @ delta4)\n",
    "    delta2 = a2 * (1 - a2) * (W3.T @ delta3)\n",
    "\n",
    "    # Gradient step\n",
    "    W2 = W2 - eta * delta2 @ x.T\n",
    "    W3 = W3 - eta * delta3 @ a2.T\n",
    "    W4 = W4 - eta * delta4 @ a3.T\n",
    "    b2 = b2 - eta * delta2\n",
    "    b3 = b3 - eta * delta3\n",
    "    b4 = b4 - eta * delta4\n",
    "  \n",
    "    # Monitor progress\n",
    "    newcost = cost(x1, x2, y, W2, W3, W4, b2, b3, b4)\n",
    "    print(f\"{counter + 1}-th iteration costs: {newcost}\")  # display cost to screen\n",
    "    # savecost(counter) = newcost;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "IvjuGQG36-6T"
   },
   "outputs": [],
   "source": [
    "def activate(x, W, b):\n",
    "    \"\"\"\n",
    "    Evaluates TANH function.\n",
    "    \n",
    "    x is the input vector, y is the output vector\n",
    "    W contains the weights, b contains the shifts\n",
    "\n",
    "    \"\"\"\n",
    "    ep = np.exp(W @ x + b)\n",
    "    en = np.exp(-(W @ x + b))\n",
    "    return (ep - en) / (ep + en)\n",
    "\n",
    "def cost(x1, x2, y, W2, W3, W4, b2, b3, b4):\n",
    "    n = len(x1)\n",
    "    costvec = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        x = np.array([[x1[i]], [x2[i]]])\n",
    "        a2 = activate(x, W2, b2)\n",
    "        a3 = activate(a2, W3, b3)\n",
    "        a4 = activate(a3, W4, b4)\n",
    "        costvec[i] = np.linalg.norm(y[:, [i]] - a4, 2)\n",
    "    costval = np.linalg.norm(costvec, 2) ** 2\n",
    "    return costval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ji2WLCL2vGgz",
    "outputId": "d9e9a6eb-a239-4af9-f8e7-45fde7429202",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-th iteration costs: 10.045385145502374\n",
      "2-th iteration costs: 10.222073605845134\n",
      "3-th iteration costs: 10.274247916553257\n",
      "4-th iteration costs: 10.494593798931788\n",
      "5-th iteration costs: 10.557018284431212\n",
      "6-th iteration costs: 10.799622585990026\n",
      "7-th iteration costs: 10.898072996190148\n",
      "8-th iteration costs: 11.18736562972386\n",
      "9-th iteration costs: 11.597017934075215\n",
      "10-th iteration costs: 11.717356117888883\n",
      "11-th iteration costs: 12.175613250009969\n",
      "12-th iteration costs: 12.34198141209542\n",
      "13-th iteration costs: 12.518257801557631\n",
      "14-th iteration costs: 12.740547199928432\n",
      "15-th iteration costs: 12.950232230287176\n",
      "16-th iteration costs: 13.15069070671872\n",
      "17-th iteration costs: 13.849231609577144\n",
      "18-th iteration costs: 14.653252390292597\n",
      "19-th iteration costs: 15.573287942881283\n",
      "20-th iteration costs: 15.941461457224985\n",
      "21-th iteration costs: 17.081674063823478\n",
      "22-th iteration costs: 18.284635579331187\n",
      "23-th iteration costs: 19.636038555639036\n",
      "24-th iteration costs: 20.959815902593764\n",
      "25-th iteration costs: 22.293543265134574\n",
      "26-th iteration costs: 23.52148684279784\n",
      "27-th iteration costs: 24.023286095179383\n",
      "28-th iteration costs: 24.492252189616288\n",
      "29-th iteration costs: 24.95584976724204\n",
      "30-th iteration costs: 25.740348962297112\n",
      "31-th iteration costs: 26.039628596842675\n",
      "32-th iteration costs: 26.559883622283383\n",
      "33-th iteration costs: 26.756128324090618\n",
      "34-th iteration costs: 26.92127942541044\n",
      "35-th iteration costs: 27.060275006405785\n",
      "36-th iteration costs: 27.26462631845092\n",
      "37-th iteration costs: 27.395314679409864\n",
      "38-th iteration costs: 27.44987859811364\n",
      "39-th iteration costs: 27.516637997819313\n",
      "40-th iteration costs: 27.558286964509637\n",
      "41-th iteration costs: 27.583628483196552\n",
      "42-th iteration costs: 27.596351312782843\n",
      "43-th iteration costs: 27.60405974869095\n",
      "44-th iteration costs: 27.605364070958707\n",
      "45-th iteration costs: 27.616472832815507\n",
      "46-th iteration costs: 27.628624237287116\n",
      "47-th iteration costs: 27.64183926534552\n",
      "48-th iteration costs: 27.6372352000009\n",
      "49-th iteration costs: 27.650815131220888\n",
      "50-th iteration costs: 27.65443604187118\n",
      "51-th iteration costs: 27.645911104208786\n",
      "52-th iteration costs: 27.643051392779054\n",
      "53-th iteration costs: 27.631295870101777\n",
      "54-th iteration costs: 27.645302010591067\n",
      "55-th iteration costs: 27.630969403185915\n",
      "56-th iteration costs: 27.644986785975927\n",
      "57-th iteration costs: 27.638953096850226\n",
      "58-th iteration costs: 27.653328566569602\n",
      "59-th iteration costs: 27.643949586411164\n",
      "60-th iteration costs: 27.629524014391727\n",
      "61-th iteration costs: 27.645044834524274\n",
      "62-th iteration costs: 27.657695450215204\n",
      "63-th iteration costs: 27.64076883107176\n",
      "64-th iteration costs: 27.65591176198381\n",
      "65-th iteration costs: 27.63771039419051\n",
      "66-th iteration costs: 27.652331010360168\n",
      "67-th iteration costs: 27.666934828086607\n",
      "68-th iteration costs: 27.64859413794038\n",
      "69-th iteration costs: 27.662649435882457\n",
      "70-th iteration costs: 27.64172541321698\n",
      "71-th iteration costs: 27.624799471462374\n",
      "72-th iteration costs: 27.607783319955974\n",
      "73-th iteration costs: 27.588706930363774\n",
      "74-th iteration costs: 27.59964335968151\n",
      "75-th iteration costs: 27.579337044402234\n",
      "76-th iteration costs: 27.56080369596513\n",
      "77-th iteration costs: 27.5729586076307\n",
      "78-th iteration costs: 27.55374741027264\n",
      "79-th iteration costs: 27.56574834593712\n",
      "80-th iteration costs: 27.541269104109023\n",
      "81-th iteration costs: 27.55450830400031\n",
      "82-th iteration costs: 27.56760425400191\n",
      "83-th iteration costs: 27.580946444935947\n",
      "84-th iteration costs: 27.56061401986072\n",
      "85-th iteration costs: 27.54225189392954\n",
      "86-th iteration costs: 27.555521544852535\n",
      "87-th iteration costs: 27.53953237571375\n",
      "88-th iteration costs: 27.551196082610854\n",
      "89-th iteration costs: 27.532925472077476\n",
      "90-th iteration costs: 27.544461205267886\n",
      "91-th iteration costs: 27.55585751425086\n",
      "92-th iteration costs: 27.537177774855973\n",
      "93-th iteration costs: 27.513984491350158\n",
      "94-th iteration costs: 27.524799636937583\n",
      "95-th iteration costs: 27.507721366405978\n",
      "96-th iteration costs: 27.519671233265438\n",
      "97-th iteration costs: 27.50585378605209\n",
      "98-th iteration costs: 27.51644550064557\n",
      "99-th iteration costs: 27.527355167279627\n",
      "100-th iteration costs: 27.512855436348367\n"
     ]
    }
   ],
   "source": [
    "n = len(x1)\n",
    "for counter in range(Niter):\n",
    "    k = rng.integers(n)  # choose a training point at random\n",
    "    x = np.array([[x1[k]], [x2[k]]])\n",
    "    # Forward pass\n",
    "    a2 = activate(x, W2, b2)\n",
    "    a3 = activate(a2, W3, b3)\n",
    "    a4 = activate(a3, W4, b4)\n",
    "\n",
    "    # Backward pass\n",
    "    delta4 = a4 * (1 - a4) * (a4 - y[:, [k]])\n",
    "    delta3 = a3 * (1 - a3) * (W4.T @ delta4)\n",
    "    delta2 = a2 * (1 - a2) * (W3.T @ delta3)\n",
    "\n",
    "    # Gradient step\n",
    "    W2 = W2 - eta * delta2 @ x.T\n",
    "    W3 = W3 - eta * delta3 @ a2.T\n",
    "    W4 = W4 - eta * delta4 @ a3.T\n",
    "    b2 = b2 - eta * delta2\n",
    "    b3 = b3 - eta * delta3\n",
    "    b4 = b4 - eta * delta4\n",
    "  \n",
    "    # Monitor progress\n",
    "    newcost = cost(x1, x2, y, W2, W3, W4, b2, b3, b4)\n",
    "    print(f\"{counter + 1}-th iteration costs: {newcost}\")  # display cost to screen\n",
    "    # savecost(counter) = newcost;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bou4_jqPfaHg",
    "outputId": "65632841-1d33-4895-aec9-d2482c955aaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n"
     ]
    }
   ],
   "source": [
    "digits = load_digits()\n",
    "print(digits.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "ekGJlwdbgj4f",
    "outputId": "8d94463b-a8bd-467d-8efc-7bc9d1e64a22"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.gray()\n",
    "plt.matshow(digits.images[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = digits.data.T\n",
    "y = pd.get_dummies(digits.target).values.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_SmRwsxzutOF",
    "outputId": "f0030397-ae5f-4383-e80a-98fe5de7f2a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(PCG64)\n"
     ]
    }
   ],
   "source": [
    "print(rng)\n",
    "# Initialize weights and biases\n",
    "W2 = 0.5 * rng.normal(size=(2, X.shape[0]))\n",
    "W3 = 0.5 * rng.normal(size=(3, 2))\n",
    "W4 = 0.5 * rng.normal(size=(y.shape[0], 3))\n",
    "b2 = 0.5 * rng.normal(size=(2, 1))\n",
    "b3 = 0.5 * rng.normal(size=(3, 1))\n",
    "b4 = 0.5 * rng.normal(size=(y.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "JslQ8vT1utzf"
   },
   "outputs": [],
   "source": [
    "# Forward and Back propagate\n",
    "eta = 0.05  # learning rate\n",
    "Niter = int(1e2)  # number of SG iterations\n",
    "savecost = np.zeros(Niter)  # value of cost function at each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "IvjuGQG36-6T"
   },
   "outputs": [],
   "source": [
    "def activate(x, W, b):\n",
    "    \"\"\"\n",
    "    Evaluates sigmoid function.\n",
    "    \n",
    "    x is the input vector, y is the output vector\n",
    "    W contains the weights, b contains the shifts\n",
    "\n",
    "    The ith component of y is activate((Wx+b)_i) where activate(z) = 1/(1+exp(-z))\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-(W @ x + b)))\n",
    "\n",
    "def cost(X, y, W2, W3, W4, b2, b3, b4):\n",
    "    n = X.shape[0]\n",
    "    costvec = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        x = X[:, [i]]\n",
    "        a2 = activate(x, W2, b2)\n",
    "        a3 = activate(a2, W3, b3)\n",
    "        a4 = activate(a3, W4, b4)\n",
    "        costvec[i] = np.linalg.norm(y[:, [i]] - a4, 2)\n",
    "    costval = np.linalg.norm(costvec, 2) ** 2\n",
    "    return costval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ji2WLCL2vGgz",
    "outputId": "d9e9a6eb-a239-4af9-f8e7-45fde7429202",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-th iteration costs: 164.0202231996849\n",
      "2-th iteration costs: 163.18812758153587\n",
      "3-th iteration costs: 162.23958704782535\n",
      "4-th iteration costs: 161.18487796905242\n",
      "5-th iteration costs: 160.33402267593962\n",
      "6-th iteration costs: 159.29374152944675\n",
      "7-th iteration costs: 158.37107715866054\n",
      "8-th iteration costs: 157.55404898780935\n",
      "9-th iteration costs: 156.61236618546423\n",
      "10-th iteration costs: 155.82009530860867\n",
      "11-th iteration costs: 154.92047964171167\n",
      "12-th iteration costs: 154.01123636798977\n",
      "13-th iteration costs: 153.20241582789234\n",
      "14-th iteration costs: 152.4623577248137\n",
      "15-th iteration costs: 151.71594785954085\n",
      "16-th iteration costs: 150.73563142623817\n",
      "17-th iteration costs: 149.87248576378556\n",
      "18-th iteration costs: 149.17367249638096\n",
      "19-th iteration costs: 148.44527963070072\n",
      "20-th iteration costs: 147.68892379146862\n",
      "21-th iteration costs: 146.93461039478572\n",
      "22-th iteration costs: 146.10230220629816\n",
      "23-th iteration costs: 145.4106005211577\n",
      "24-th iteration costs: 144.75340627356712\n",
      "25-th iteration costs: 143.9074093904877\n",
      "26-th iteration costs: 143.2235538938482\n",
      "27-th iteration costs: 142.5548547133999\n",
      "28-th iteration costs: 141.85036179520517\n",
      "29-th iteration costs: 141.2008547784762\n",
      "30-th iteration costs: 140.54140670280634\n",
      "31-th iteration costs: 139.8240507578588\n",
      "32-th iteration costs: 139.22226782318785\n",
      "33-th iteration costs: 138.52500351197747\n",
      "34-th iteration costs: 137.69045091987272\n",
      "35-th iteration costs: 137.02181891772142\n",
      "36-th iteration costs: 136.20096374999721\n",
      "37-th iteration costs: 135.45155248924587\n",
      "38-th iteration costs: 134.71170843163378\n",
      "39-th iteration costs: 134.1235258510342\n",
      "40-th iteration costs: 133.5420686749094\n",
      "41-th iteration costs: 132.75362518861397\n",
      "42-th iteration costs: 132.02189880123456\n",
      "43-th iteration costs: 131.36754920806874\n",
      "44-th iteration costs: 130.71046714125328\n",
      "45-th iteration costs: 130.1944457994232\n",
      "46-th iteration costs: 129.43639219204488\n",
      "47-th iteration costs: 128.6462570253002\n",
      "48-th iteration costs: 128.0774141274796\n",
      "49-th iteration costs: 127.339093319726\n",
      "50-th iteration costs: 126.85555750028415\n",
      "51-th iteration costs: 126.30326628821733\n",
      "52-th iteration costs: 125.69336653847306\n",
      "53-th iteration costs: 125.15143787540107\n",
      "54-th iteration costs: 124.55257438953934\n",
      "55-th iteration costs: 123.96151919764196\n",
      "56-th iteration costs: 123.2227404255097\n",
      "57-th iteration costs: 122.6451540428494\n",
      "58-th iteration costs: 121.9560909231444\n",
      "59-th iteration costs: 121.30004011468752\n",
      "60-th iteration costs: 120.6535156354483\n",
      "61-th iteration costs: 120.093746836465\n",
      "62-th iteration costs: 119.61552672333382\n",
      "63-th iteration costs: 119.20267253979966\n",
      "64-th iteration costs: 118.70834201908684\n",
      "65-th iteration costs: 118.0578594019186\n",
      "66-th iteration costs: 117.6111514744387\n",
      "67-th iteration costs: 116.93690621846639\n",
      "68-th iteration costs: 116.50227772342942\n",
      "69-th iteration costs: 115.84114477432912\n",
      "70-th iteration costs: 115.18839875471235\n",
      "71-th iteration costs: 114.67735948163462\n",
      "72-th iteration costs: 114.31115577157435\n",
      "73-th iteration costs: 113.81063206091719\n",
      "74-th iteration costs: 113.35910670928043\n",
      "75-th iteration costs: 112.74985094855451\n",
      "76-th iteration costs: 112.40232706197753\n",
      "77-th iteration costs: 111.91987821434408\n",
      "78-th iteration costs: 111.4854796483959\n",
      "79-th iteration costs: 110.99860627965231\n",
      "80-th iteration costs: 110.51869479785776\n",
      "81-th iteration costs: 109.94872307882167\n",
      "82-th iteration costs: 109.48064987789081\n",
      "83-th iteration costs: 109.01881811607872\n",
      "84-th iteration costs: 108.56440522309421\n",
      "85-th iteration costs: 108.11675481180052\n",
      "86-th iteration costs: 107.71204455885237\n",
      "87-th iteration costs: 107.19135626124881\n",
      "88-th iteration costs: 106.75124168215989\n",
      "89-th iteration costs: 106.31827742992394\n",
      "90-th iteration costs: 105.89095417687425\n",
      "91-th iteration costs: 105.60192776749976\n",
      "92-th iteration costs: 105.2474243852219\n",
      "93-th iteration costs: 104.82965976053488\n",
      "94-th iteration costs: 104.45181598385881\n",
      "95-th iteration costs: 104.04363124394862\n",
      "96-th iteration costs: 103.53898219925375\n",
      "97-th iteration costs: 103.04117203465901\n",
      "98-th iteration costs: 102.52529332407171\n",
      "99-th iteration costs: 102.19987686132073\n",
      "100-th iteration costs: 101.73982558692553\n"
     ]
    }
   ],
   "source": [
    "n = X.shape[0]\n",
    "for counter in range(Niter):\n",
    "    k = rng.integers(n)  # choose a training point at random\n",
    "    x = X[:, [k]]\n",
    "    # Forward pass\n",
    "    a2 = activate(x, W2, b2)\n",
    "    a3 = activate(a2, W3, b3)\n",
    "    a4 = activate(a3, W4, b4)\n",
    "\n",
    "    # Backward pass\n",
    "    delta4 = a4 * (1 - a4) * (a4 - y[:, [k]])\n",
    "    delta3 = a3 * (1 - a3) * (W4.T @ delta4)\n",
    "    delta2 = a2 * (1 - a2) * (W3.T @ delta3)\n",
    "\n",
    "    # Gradient step\n",
    "    W2 = W2 - eta * delta2 @ x.T\n",
    "    W3 = W3 - eta * delta3 @ a2.T\n",
    "    W4 = W4 - eta * delta4 @ a3.T\n",
    "    b2 = b2 - eta * delta2\n",
    "    b3 = b3 - eta * delta3\n",
    "    b4 = b4 - eta * delta4\n",
    "  \n",
    "    # Monitor progress\n",
    "    newcost = cost(X, y, W2, W3, W4, b2, b3, b4)\n",
    "    print(f\"{counter + 1}-th iteration costs: {newcost}\")  # display cost to screen\n",
    "    # savecost(counter) = newcost;"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MATH665 - Project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
